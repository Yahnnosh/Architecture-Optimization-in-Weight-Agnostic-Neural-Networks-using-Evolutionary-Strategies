{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras import layers, models, Model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "#from vis.utils.utils import apply_modifications\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "outputs": [],
   "source": [
    "activation_functions = {\n",
    "    'tanh': tf.tanh,\n",
    "    'relu': tf.nn.relu,\n",
    "    'sigmoid': tf.nn.sigmoid,\n",
    "    'linear': tf.keras.activations.linear,\n",
    "    'softmax': tf.nn.softmax,\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Loading Data**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 250 ms\n",
      "Wall time: 236 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "t0 = time.time()    # compute total execution time\n",
    "\n",
    "# numpy\n",
    "_, (X_test, y_test) = mnist.load_data() # only care  about X_test\n",
    "\n",
    "X_test = X_test.reshape(10000, 784).astype(np.float32) / 255.0\n",
    "y_test = to_categorical(y_test)  # one-hot encoding\n",
    "\n",
    "# tensorflow\n",
    "X_test = tf.convert_to_tensor(X_test)\n",
    "y_test = tf.convert_to_tensor(y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Model Definition**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "outputs": [],
   "source": [
    "MUTATE_RATE_MATRIX = 0.3\n",
    "MUTATE_RATE_BIAS = 0.1\n",
    "MUTATE_RATE_ACTIVATION_FUNCTION = 0.1\n",
    "GAUSSIAN_NOISE_STDDEV = 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class MultiLayerPerceptron(Model):\n",
    "    def __init__(self, matrix1, bias1, activation1, matrix2, bias2, activation2):\n",
    "        \"\"\"\n",
    "        Weight gnostic multi-layer feed forward neural network\n",
    "        :param params: Params have to be in form: (matrix1=..., bias1=..., activation1=..., matrix2=..., ...)\n",
    "        \"\"\"\n",
    "        super(MultiLayerPerceptron, self).__init__()\n",
    "\n",
    "        self.linear1 = tf.keras.layers.Dense(32,\n",
    "                                             activation=activation_functions[activation1],\n",
    "                                             kernel_initializer=tf.keras.initializers.Constant(matrix1),\n",
    "                                             bias_initializer=tf.keras.initializers.Constant(bias1))\n",
    "        self.linear2 = tf.keras.layers.Dense(10,\n",
    "                                             activation=activation_functions[activation2],\n",
    "                                             kernel_initializer=tf.keras.initializers.Constant(matrix2),\n",
    "                                             bias_initializer=tf.keras.initializers.Constant(bias2))\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.linear1(inputs)\n",
    "        x = self.linear2(x)\n",
    "        return x\n",
    "\n",
    "    '''def fitness(self):\n",
    "        return self.evaluate(X_test, y_test, verbose=0)[1]'''\n",
    "\n",
    "    def mutate(self):\n",
    "        self.build(X_test.shape)   # necessary to build params # TODO: required here?\n",
    "        for layer_name in ('linear1', 'linear2'):\n",
    "            layer = getattr(self, layer_name)\n",
    "\n",
    "            # matrix\n",
    "            matrix = layer.kernel\n",
    "            mutation_stencil = tf.cast(tf.reshape(tf.random.categorical(\n",
    "                tf.math.log([[1 - MUTATE_RATE_MATRIX, MUTATE_RATE_MATRIX]]),\n",
    "                matrix.shape[0] * matrix.shape[1]), matrix.shape), tf.float32)\n",
    "            noise = tf.random.normal(mean=0.0, stddev=GAUSSIAN_NOISE_STDDEV, shape=matrix.shape)  # TODO: tune stddev\n",
    "            matrix = matrix + tf.multiply(mutation_stencil, noise)\n",
    "\n",
    "            # bias\n",
    "            bias = layer.bias\n",
    "            mutation_stencil = tf.cast(tf.reshape(tf.random.categorical(\n",
    "                tf.math.log([[1 - MUTATE_RATE_BIAS, MUTATE_RATE_BIAS]]),\n",
    "                bias.shape[0]), bias.shape), tf.float32)\n",
    "            noise = tf.random.normal(mean=0.0, stddev=GAUSSIAN_NOISE_STDDEV, shape=bias.shape)  # TODO: tune stddev\n",
    "            bias = bias + tf.multiply(mutation_stencil, noise)\n",
    "\n",
    "            # activation\n",
    "            cleaner = lambda x: 'softmax' if x=='softmax_v2' else x\n",
    "            activation = cleaner(layer.activation.__name__)\n",
    "            if random.uniform(0, 1) < MUTATE_RATE_ACTIVATION_FUNCTION:\n",
    "                activation = random.choice(list(activation_functions.keys()))\n",
    "\n",
    "            try:\n",
    "                setattr(self, layer_name,\n",
    "                        tf.keras.layers.Dense(layer.units,\n",
    "                                              activation=activation_functions[activation],\n",
    "                                              kernel_initializer=tf.keras.initializers.Constant(matrix),\n",
    "                                              bias_initializer=tf.keras.initializers.Constant(bias))\n",
    "                        )\n",
    "            except KeyError:\n",
    "                print(activation)\n",
    "\n",
    "        self.compile(metrics=['accuracy'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Population():\n",
    "    def __init__(self, size=10, n_survivors=5):\n",
    "        self.generation = 0\n",
    "        self.size = size\n",
    "        self.n_survivors = n_survivors\n",
    "        self.elite = None\n",
    "        self.fitness = None\n",
    "        self.fitness_generation = -1  # generation when fitness was evaluated\n",
    "\n",
    "        # initialization (gaussian)\n",
    "        # TODO: max, min for now 7-bit integers\n",
    "        self.organisms = []\n",
    "        for _ in range(size):\n",
    "            # TODO: for now fixed architecture\n",
    "            bias1 = tf.random.normal(mean=0.0, stddev=1.0, shape=[32, 1])\n",
    "            matrix1 = tf.random.normal(mean=0.0, stddev=1.0, shape=[32, 784])\n",
    "            activation1 = 'sigmoid'\n",
    "\n",
    "            bias2 = tf.random.normal(mean=0.0, stddev=1.0, shape=[10, 1])\n",
    "            matrix2 = tf.random.normal(mean=0.0, stddev=1.0, shape=[10, 32])\n",
    "            activation2 = 'softmax'\n",
    "\n",
    "            model = MultiLayerPerceptron(matrix1, bias1, activation1, matrix2, bias2, activation2)\n",
    "            model.compile(metrics=['accuracy'])\n",
    "\n",
    "            self.organisms.append(model)\n",
    "\n",
    "        self.history = [(max(self.organism_fitness()), self.average_fitness())]   # fitness of population over all generations\n",
    "\n",
    "    def organism_fitness(self):\n",
    "        if self.generation != self.fitness_generation:\n",
    "            self.fitness = [organism.evaluate(X_test, y_test, verbose=0)[1] for organism in self.organisms]\n",
    "            self.fitness_generation = self.generation\n",
    "\n",
    "        return self.fitness\n",
    "\n",
    "    def average_fitness(self):\n",
    "        organism_fitness = self.organism_fitness()\n",
    "        return sum(organism_fitness) / len(organism_fitness)\n",
    "\n",
    "    def max_fitness(self):\n",
    "        return max(self.organism_fitness())\n",
    "\n",
    "    def selection(self):\n",
    "        organism_fitness = self.organism_fitness()\n",
    "\n",
    "        # elitism (n=1)\n",
    "        elite_index = np.argmax(organism_fitness)\n",
    "        self.elite = self.organisms.pop(elite_index)\n",
    "        organism_fitness.pop(elite_index)\n",
    "\n",
    "        probabilities = [fitness / sum(organism_fitness) for fitness in organism_fitness]  # normalized\n",
    "        survivors = np.random.choice(self.organisms,\n",
    "                                     size=self.n_survivors - 1,\n",
    "                                     p=probabilities,\n",
    "                                     replace=False)    # TODO: works without replacement and p?\n",
    "        return [survivor for survivor in survivors]\n",
    "\n",
    "    def crossover(self, parents):\n",
    "        # TODO: for different type of networks\n",
    "        # TODO: correct?\n",
    "        children = []\n",
    "        while len(children) < (self.size - 1):\n",
    "            [father, mother] = random.sample(parents + [self.elite], k=2)  # sample without replacement\n",
    "\n",
    "            # TODO: for now assume same no of layers\n",
    "            # TODO: create new model - efficient?\n",
    "            # TODO: init with **kwargs -> child init easy\n",
    "            child_params = {}\n",
    "            for i, layer_name in enumerate(['linear1', 'linear2']):\n",
    "                father_layer = getattr(father, layer_name)\n",
    "                mother_layer = getattr(mother, layer_name)\n",
    "\n",
    "                # matrix - uniform crossover\n",
    "                father_matrix = father_layer.kernel\n",
    "                mother_matrix = mother_layer.kernel\n",
    "\n",
    "                father_stencil = tf.round(tf.random.uniform(father_matrix.shape))\n",
    "                mother_stencil = - (father_stencil - 1)\n",
    "\n",
    "                child_matrix = tf.multiply(father_stencil, father_matrix) + tf.multiply(mother_stencil, mother_matrix)\n",
    "                child_params['child_matrix' + str(i+1)] = child_matrix\n",
    "\n",
    "                # bias - uniform crossover\n",
    "                father_bias = father_layer.bias\n",
    "                mother_bias = mother_layer.bias\n",
    "\n",
    "                father_stencil = tf.round(tf.random.uniform(father_bias.shape))\n",
    "                mother_stencil = - (father_stencil - 1)\n",
    "\n",
    "                child_bias = tf.multiply(father_stencil, father_bias) + tf.multiply(mother_stencil, mother_bias)\n",
    "                child_params['child_bias' + str(i+1)] = child_bias\n",
    "\n",
    "                # activation\n",
    "                cleaner = lambda x: 'softmax' if x=='softmax_v2' else x\n",
    "                father_activation = cleaner(father_layer.activation.__name__)\n",
    "                mother_activation = cleaner(mother_layer.activation.__name__)\n",
    "\n",
    "                child_activation = father_activation if (random.uniform(0, 1) < 0.5) else mother_activation\n",
    "                child_params['child_activation' + str(i+1)] = child_activation\n",
    "\n",
    "            model = MultiLayerPerceptron(matrix1=child_params['child_matrix1'],\n",
    "                                         bias1=child_params['child_bias1'],\n",
    "                                         activation1=child_params['child_activation1'],\n",
    "                                         matrix2=child_params['child_matrix2'],\n",
    "                                         bias2=child_params['child_bias2'],\n",
    "                                         activation2=child_params['child_activation2']\n",
    "                                         )\n",
    "            model.compile(metrics=['accuracy']) # TODO: necessary??\n",
    "            model.build(X_test.shape)   # necessary to build params\n",
    "            children.append(model)\n",
    "\n",
    "        return children\n",
    "\n",
    "    def mutate(self, organisms):\n",
    "        for organism in organisms:\n",
    "            organism.mutate()\n",
    "\n",
    "    def breed(self):\n",
    "        time_debug = ''\n",
    "\n",
    "        t_a = time.time()\n",
    "        parents = self.selection()\n",
    "        t_b = time.time()\n",
    "        time_debug += 'selection time: {}s - '.format(round(t_b - t_a, 4))\n",
    "\n",
    "        t_a = time.time()\n",
    "        children = self.crossover(parents)\n",
    "        t_b = time.time()\n",
    "        time_debug += 'crossover time: {}s - '.format(round(t_b - t_a, 4))\n",
    "\n",
    "        t_a = time.time()\n",
    "        self.mutate(children)  # TODO: mGA or GA?\n",
    "        t_b = time.time()\n",
    "        time_debug += 'mutation time: {}s - '.format(round(t_b - t_a, 4))\n",
    "\n",
    "        print(time_debug)\n",
    "\n",
    "        self.organisms = children + [self.elite]\n",
    "        self.generation += 1\n",
    "        self.history.append((self.max_fitness(), self.average_fitness()))\n",
    "\n",
    "    def plot(self):\n",
    "        plt.figure()\n",
    "        plt.plot(np.arange(self.generation + 1), [score[0] for score in self.history],\n",
    "                 label='max fitness')\n",
    "        plt.plot(np.arange(self.generation + 1), [score[1] for score in self.history],\n",
    "                 label='avg fitness', alpha=0.6)\n",
    "        plt.title('Population fitness' + ' (n=' + str(self.size) + ')')\n",
    "        plt.xlabel('Generations')\n",
    "        plt.ylabel('Fitness score (accuracy)')\n",
    "        plt.legend()\n",
    "        plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Training**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# initialization\n",
    "GENERATIONS = 100\n",
    "POPULATION_SIZE = 10\n",
    "SURVIVORS = 5"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gen 31 : [0.1662999987602234, 0.17170000076293945, 0.14069999754428864, 0.1923999935388565, 0.14910000562667847, 0.18320000171661377, 0.16670000553131104, 0.12020000070333481, 0.14079999923706055, 0.20430000126361847] - max: 0.20430000126361847 (13.31s)\n",
      "selection time: 2.521s - crossover time: 0.1235s - mutation time: 0.1245s - \n",
      "Gen 32 : [0.13030000030994415, 0.15809999406337738, 0.15240000188350677, 0.2037000060081482, 0.1590999960899353, 0.14720000326633453, 0.14249999821186066, 0.16009999811649323, 0.17910000681877136, 0.20430000126361847] - max: 0.20430000126361847 (12.94s)\n",
      "selection time: 2.514s - crossover time: 0.203s - mutation time: 0.1475s - \n",
      "Gen 33 : [0.19509999454021454, 0.11640000343322754, 0.18809999525547028, 0.10949999839067459, 0.1664000004529953, 0.1518000066280365, 0.14139999449253082, 0.16760000586509705, 0.18970000743865967, 0.20430000126361847] - max: 0.20430000126361847 (12.73s)\n",
      "selection time: 2.478s - crossover time: 0.1225s - mutation time: 0.168s - \n",
      "Gen 34 : [0.15049999952316284, 0.1915999948978424, 0.18289999663829803, 0.1371999979019165, 0.1517000049352646, 0.1899999976158142, 0.1193000003695488, 0.17710000276565552, 0.1679999977350235, 0.20430000126361847] - max: 0.20430000126361847 (12.37s)\n",
      "selection time: 2.0645s - crossover time: 0.131s - mutation time: 0.131s - \n",
      "Gen 35 : [0.19099999964237213, 0.1362999975681305, 0.1574999988079071, 0.06970000267028809, 0.18240000307559967, 0.18639999628067017, 0.1647000014781952, 0.16840000450611115, 0.17159999907016754, 0.20430000126361847] - max: 0.20430000126361847 (15.62s)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[1;32mIn [130]\u001B[0m, in \u001B[0;36m<cell line: 14>\u001B[1;34m()\u001B[0m\n\u001B[0;32m     14\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m generation \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m1\u001B[39m, GENERATIONS):\n\u001B[0;32m     15\u001B[0m     \u001B[38;5;66;03m# breed new population\u001B[39;00m\n\u001B[0;32m     16\u001B[0m     t1 \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[1;32m---> 17\u001B[0m     \u001B[43mpopulation\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbreed\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     19\u001B[0m     \u001B[38;5;66;03m# evaluate new population\u001B[39;00m\n\u001B[0;32m     20\u001B[0m     population_fitness \u001B[38;5;241m=\u001B[39m population\u001B[38;5;241m.\u001B[39morganism_fitness()\n",
      "Input \u001B[1;32mIn [128]\u001B[0m, in \u001B[0;36mPopulation.breed\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    114\u001B[0m time_debug \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m    116\u001B[0m t_a \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[1;32m--> 117\u001B[0m parents \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mselection\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    118\u001B[0m t_b \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[0;32m    119\u001B[0m time_debug \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mselection time: \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124ms - \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\u001B[38;5;28mround\u001B[39m(t_b \u001B[38;5;241m-\u001B[39m t_a, \u001B[38;5;241m4\u001B[39m))\n",
      "Input \u001B[1;32mIn [128]\u001B[0m, in \u001B[0;36mPopulation.selection\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     38\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mselection\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m---> 39\u001B[0m     organism_fitness \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43morganism_fitness\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     41\u001B[0m     \u001B[38;5;66;03m# elitism (n=1)\u001B[39;00m\n\u001B[0;32m     42\u001B[0m     elite_index \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39margmax(organism_fitness)\n",
      "Input \u001B[1;32mIn [128]\u001B[0m, in \u001B[0;36mPopulation.organism_fitness\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     28\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21morganism_fitness\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m---> 29\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m [organism\u001B[38;5;241m.\u001B[39mfitness() \u001B[38;5;28;01mfor\u001B[39;00m organism \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39morganisms]\n",
      "Input \u001B[1;32mIn [128]\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m     28\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21morganism_fitness\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m---> 29\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m [\u001B[43morganism\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfitness\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m organism \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39morganisms]\n",
      "Input \u001B[1;32mIn [127]\u001B[0m, in \u001B[0;36mMultiLayerPerceptron.fitness\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     23\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfitness\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m---> 24\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mevaluate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_test\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_test\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m[\u001B[38;5;241m1\u001B[39m]\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\TF_CPU\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     62\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     63\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 64\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     65\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# pylint: disable=broad-except\u001B[39;00m\n\u001B[0;32m     66\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\TF_CPU\\lib\\site-packages\\keras\\engine\\training.py:1710\u001B[0m, in \u001B[0;36mModel.evaluate\u001B[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001B[0m\n\u001B[0;32m   1708\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_test_counter\u001B[38;5;241m.\u001B[39massign(\u001B[38;5;241m0\u001B[39m)\n\u001B[0;32m   1709\u001B[0m callbacks\u001B[38;5;241m.\u001B[39mon_test_begin()\n\u001B[1;32m-> 1710\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m _, iterator \u001B[38;5;129;01min\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39menumerate_epochs():  \u001B[38;5;66;03m# Single epoch.\u001B[39;00m\n\u001B[0;32m   1711\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreset_metrics()\n\u001B[0;32m   1712\u001B[0m   \u001B[38;5;28;01mwith\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mcatch_stop_iteration():\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\TF_CPU\\lib\\site-packages\\keras\\engine\\data_adapter.py:1191\u001B[0m, in \u001B[0;36mDataHandler.enumerate_epochs\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1189\u001B[0m \u001B[38;5;124;03m\"\"\"Yields `(epoch, tf.data.Iterator)`.\"\"\"\u001B[39;00m\n\u001B[0;32m   1190\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_truncate_execution_to_epoch():\n\u001B[1;32m-> 1191\u001B[0m   data_iterator \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43miter\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dataset\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1192\u001B[0m   \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_initial_epoch, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_epochs):\n\u001B[0;32m   1193\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_insufficient_data:  \u001B[38;5;66;03m# Set by `catch_stop_iteration`.\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\TF_CPU\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:486\u001B[0m, in \u001B[0;36mDatasetV2.__iter__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    484\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m context\u001B[38;5;241m.\u001B[39mexecuting_eagerly() \u001B[38;5;129;01mor\u001B[39;00m ops\u001B[38;5;241m.\u001B[39minside_function():\n\u001B[0;32m    485\u001B[0m   \u001B[38;5;28;01mwith\u001B[39;00m ops\u001B[38;5;241m.\u001B[39mcolocate_with(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_variant_tensor):\n\u001B[1;32m--> 486\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43miterator_ops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mOwnedIterator\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    487\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    488\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`tf.data.Dataset` only supports Python-style \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    489\u001B[0m                      \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124miteration in eager mode or within tf.function.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\TF_CPU\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:755\u001B[0m, in \u001B[0;36mOwnedIterator.__init__\u001B[1;34m(self, dataset, components, element_spec)\u001B[0m\n\u001B[0;32m    751\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m (components \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m element_spec \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m    752\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    753\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWhen `dataset` is provided, `element_spec` and `components` must \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    754\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnot be specified.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m--> 755\u001B[0m   \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_create_iterator\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    757\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_next_call_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\TF_CPU\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:787\u001B[0m, in \u001B[0;36mOwnedIterator._create_iterator\u001B[1;34m(self, dataset)\u001B[0m\n\u001B[0;32m    782\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    783\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iterator_resource, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_deleter \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m    784\u001B[0m       gen_dataset_ops\u001B[38;5;241m.\u001B[39manonymous_iterator_v2(\n\u001B[0;32m    785\u001B[0m           output_types\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_flat_output_types,\n\u001B[0;32m    786\u001B[0m           output_shapes\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_flat_output_shapes))\n\u001B[1;32m--> 787\u001B[0m   \u001B[43mgen_dataset_ops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmake_iterator\u001B[49m\u001B[43m(\u001B[49m\u001B[43mds_variant\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_iterator_resource\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    788\u001B[0m   \u001B[38;5;66;03m# Delete the resource when this object is deleted\u001B[39;00m\n\u001B[0;32m    789\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_resource_deleter \u001B[38;5;241m=\u001B[39m IteratorResourceDeleter(\n\u001B[0;32m    790\u001B[0m       handle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iterator_resource,\n\u001B[0;32m    791\u001B[0m       deleter\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_deleter)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\TF_CPU\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py:3314\u001B[0m, in \u001B[0;36mmake_iterator\u001B[1;34m(dataset, iterator, name)\u001B[0m\n\u001B[0;32m   3312\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m tld\u001B[38;5;241m.\u001B[39mis_eager:\n\u001B[0;32m   3313\u001B[0m   \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 3314\u001B[0m     _result \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_FastPathExecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   3315\u001B[0m \u001B[43m      \u001B[49m\u001B[43m_ctx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mMakeIterator\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3316\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _result\n\u001B[0;32m   3317\u001B[0m   \u001B[38;5;28;01mexcept\u001B[39;00m _core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# initial population\n",
    "print('Starting training')\n",
    "t_training = time.time()\n",
    "population = Population(size=POPULATION_SIZE, n_survivors=SURVIVORS)\n",
    "population_fitness = population.organism_fitness()\n",
    "max_fitness = population.max_fitness()\n",
    "t2 = time.time()\n",
    "print('Gen', 0, ':',\n",
    "      population_fitness, '- max:',\n",
    "      max_fitness,\n",
    "      '({}s)'.format(round(t2 - t_training, 2)))\n",
    "\n",
    "# future populations\n",
    "for generation in range(1, GENERATIONS):\n",
    "    # breed new population\n",
    "    t1 = time.time()\n",
    "    population.breed()\n",
    "\n",
    "    # evaluate new population\n",
    "    ta = time.time\n",
    "    population_fitness = population.organism_fitness()\n",
    "    max_fitness = population.max_fitness()\n",
    "    t2 = time.time()\n",
    "    print('crossover time: {}s - '.format(round(t2 - ta, 4)))\n",
    "\n",
    "    print('Gen', generation, ':',\n",
    "          population_fitness, '- max:',\n",
    "          max_fitness,\n",
    "          '({}s)'.format(round(t2 - t1, 2)))\n",
    "\n",
    "print('Finished training ({})'.format(round(time.time() - t_training, 2)))\n",
    "print('\\nTotal computation time: ({}s)'.format(round(time.time() - t0, 2)))\n",
    "\n",
    "# performance of population\n",
    "population.plot()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "bias1 = tf.random.normal(mean=0.0, stddev=1.0, shape=(32,))\n",
    "matrix1 = tf.random.normal(mean=0.0, stddev=1.0, shape=(784, 32))\n",
    "bias2 = tf.random.normal(mean=0.0, stddev=1.0, shape=(10, ))\n",
    "matrix2 = tf.random.normal(mean=0.0, stddev=1.0, shape=(32, 10))\n",
    "\n",
    "lin = LinModel(matrix1=matrix1, bias1=bias1)\n",
    "lin.compile(metrics=['accuracy'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%timeit\n",
    "lin.evaluate(X_test, y_test, verbose=0)[1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}