{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    z = x - np.max(x)   # overflow protection (softmax(x) = softmax(x - const))\n",
    "    return np.exp(z) / np.sum(np.exp(z))\n",
    "\n",
    "activation_functions = {\n",
    "    'tanh': np.tanh,\n",
    "    'relu': (lambda x: np.maximum(0, x)),\n",
    "    'sigmoid': (lambda x: 1 / (1 + np.exp(-x))),\n",
    "    'linear': (lambda x: x),\n",
    "    'softmax': softmax\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Loading Data**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 359 ms\n",
      "Wall time: 334 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "t0 = time.time()\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train = X_train.reshape(-1, np.shape(X_train)[1] * np.shape(X_train)[1]).astype(np.float32) / 255.0\n",
    "X_test = X_test.reshape(-1, np.shape(X_test)[1] * np.shape(X_test)[1]).astype(np.float32) / 255.0\n",
    "y_train = to_categorical(y_train)   # one-hot encoding\n",
    "y_test = to_categorical(y_test)  # one-hot encoding"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Network Definition**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "class Layer():\n",
    "    def __init__(self, connectivity_matrix, bias, activation_function, output_layer=False):\n",
    "        self.connectivity_matrix = connectivity_matrix\n",
    "        self.bias = bias\n",
    "        if output_layer:\n",
    "            assert(activation_function == 'softmax'), 'output layer must use softmax'\n",
    "        self.activation_function = activation_function\n",
    "        self.output_layer = output_layer    # final 10 neuron layer (activation fixed to softmax)\n",
    "\n",
    "        # TODO: tune\n",
    "        self.mutate_rate_weight = 0.1\n",
    "        self.mutate_rate_connections = 0.3\n",
    "        self.mutate_rate_bias = 0.1\n",
    "        self.mutate_rate_activation_function = 0.1\n",
    "\n",
    "    def forward(self, input):\n",
    "        return activation_functions[self.activation_function](self.connectivity_matrix @ input + self.bias)\n",
    "\n",
    "    def bitstring_mutation(self, param, n_bits=7):\n",
    "        try:\n",
    "            # TODO: check if correct (esp. sign)\n",
    "            bitstring = bin(self.bias)[2:].zfill(n_bits)\n",
    "            temp = ''\n",
    "            sign = +1 if random.uniform(0, 1) else -1\n",
    "            for i in range(len(bitstring)):\n",
    "                if random.uniform(0, 1) < self.mutate_rate_bias:\n",
    "                    temp2 = '0' if bitstring[i] == '1' else '1'\n",
    "                    temp += temp2\n",
    "                else:\n",
    "                    temp += bitstring[i]\n",
    "            return sign * int(temp, 2)\n",
    "        except (TypeError):\n",
    "            bitstring = bin(self.bias)[2:].zfill(n_bits)\n",
    "            temp = ''\n",
    "            sign = +1 if random.uniform(0, 1) else -1\n",
    "            for i in range(len(bitstring)):\n",
    "                if random.uniform(0, 1) < self.mutate_rate_bias:\n",
    "                    temp2 = '0' if bitstring[i] == '1' else '1'\n",
    "                    temp += temp2\n",
    "                else:\n",
    "                    temp += bitstring[i]\n",
    "            print(param, temp)\n",
    "\n",
    "\n",
    "    def mutate(self):\n",
    "        # TODO: quite arbitrary, inefficient and do negative numbers work?\n",
    "        # TODO: only works for integer as of now\n",
    "\n",
    "        # connectivity matrix\n",
    "        # TODO: row, col correct?\n",
    "        for row in range(np.shape(self.connectivity_matrix)[0]):\n",
    "            for col in range(np.shape(self.connectivity_matrix)[1]):\n",
    "                if random.uniform(0, 1) < self.mutate_rate_connections:\n",
    "                    self.connectivity_matrix[row][col] = self.bitstring_mutation(self.connectivity_matrix[row][col], n_bits=7)\n",
    "\n",
    "        # bias\n",
    "        self.bias = self.bitstring_mutation(self.bias, n_bits=7)\n",
    "\n",
    "        # activation function\n",
    "        if not self.output_layer:\n",
    "            if random.uniform(0, 1) < self.mutate_rate_activation_function:\n",
    "                self.activation_function = random.choice(list(activation_functions.keys()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "class Network():\n",
    "    def __init__(self, layers):\n",
    "        self.layers = layers    # structured (feedforward) array of layers\n",
    "\n",
    "    def forward(self, input):\n",
    "        temp = input\n",
    "        for layer in self.layers:\n",
    "            temp = layer.forward(temp)\n",
    "        return temp\n",
    "\n",
    "    def evaluate(self):  # TODO: slow? (on cpu ~0.55s per call)\n",
    "        accuracy = 0\n",
    "        for x, y in zip(X_test, y_test):\n",
    "            y_pred = np.argmax(self.forward(x.reshape(-1)))  # class with highest value\n",
    "            y_true = np.argmax(y)\n",
    "            if y_pred == y_true:\n",
    "                accuracy += 1\n",
    "        return accuracy / np.shape(X_test)[0]\n",
    "\n",
    "    def mutate(self):\n",
    "        for layer in self.layers:\n",
    "            layer.mutate()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "class Population():\n",
    "    def __init__(self, size=10, n_survivors=5):\n",
    "        self.generation = 0\n",
    "        self.size = size\n",
    "        self.n_survivors = n_survivors  # TODO: for now must be odd number (1 elite + odd breeders)\n",
    "        self.elite = None\n",
    "\n",
    "        # initialization (gaussian) # TODO: better (quite random now - e.g. 32 hidden neurons)\n",
    "        # TODO: max, min for now 7-bit integers\n",
    "        self.organisms = []\n",
    "        for i in range(size):\n",
    "            self.organisms.append(Network([\n",
    "                Layer(\n",
    "                    connectivity_matrix=np.clip(np.random.normal(loc=0.0, scale=1.0, size=(32, 784)), a_min=-128, a_max=128).astype(int),\n",
    "                    bias=min(128, max(-128, int(np.random.normal(loc=0.0, scale=1.0)))),\n",
    "                    activation_function='sigmoid',\n",
    "                    output_layer=False\n",
    "                ),\n",
    "                Layer(\n",
    "                    connectivity_matrix=np.clip(np.random.normal(loc=0.0, scale=1.0, size=(10, 32)), a_min=-128, a_max=128).astype(int),\n",
    "                    bias=min(128, max(-128, int(np.random.normal(loc=0.0, scale=1.0)))),\n",
    "                    activation_function='softmax',\n",
    "                    output_layer=True\n",
    "                )\n",
    "            ]))\n",
    "\n",
    "        self.history = [(max(self.organism_fitness()), self.average_fitness())]   # fitness of population over all generations\n",
    "\n",
    "    def organism_fitness(self):\n",
    "        return [organism.evaluate() for organism in self.organisms]\n",
    "\n",
    "    def average_fitness(self):\n",
    "        organism_fitness = self.organism_fitness()\n",
    "        return sum(organism_fitness) / len(organism_fitness)\n",
    "\n",
    "    def max_fitness(self):\n",
    "        return max(self.organism_fitness())\n",
    "\n",
    "    def selection(self):\n",
    "        organism_fitness = self.organism_fitness()\n",
    "\n",
    "        # elitism (n=1)\n",
    "        elite_index = np.argmax(organism_fitness)\n",
    "        self.elite = self.organisms.pop(elite_index)\n",
    "        organism_fitness.pop(elite_index)\n",
    "\n",
    "        probabilities = [fitness / sum(organism_fitness) for fitness in organism_fitness]  # normalized\n",
    "        survivors = np.random.choice(self.organisms,\n",
    "                                     size=self.n_survivors - 1,\n",
    "                                     p=probabilities,\n",
    "                                     replace=False)    # TODO: works without replacement and p?\n",
    "        return [survivor for survivor in survivors]\n",
    "\n",
    "    def crossover(self, parents):\n",
    "        # TODO: for different type of networks\n",
    "        # TODO: correct?\n",
    "        children = []\n",
    "        while len(children) < (self.size - 1):\n",
    "            [father, mother] = random.sample(parents + [self.elite], k=2)  # sample without replacement\n",
    "            layers = []\n",
    "\n",
    "            # TODO: for now assume same no of layers\n",
    "            for father_gene, mother_gene in zip(father.layers, mother.layers):\n",
    "                # full gene crossover # TODO: good?\n",
    "                child_bias = father_gene.bias if (random.uniform(0, 1) < 0.5) else mother_gene.bias\n",
    "                child_activation_function = father_gene.activation_function if \\\n",
    "                    (random.uniform(0, 1) < 0.5) else mother_gene.activation_function\n",
    "\n",
    "                # uniform (bit-wise) crossover # TODO: good?\n",
    "                child_connectivity_matrix = np.zeros(np.shape(father_gene.connectivity_matrix))\n",
    "                for row in range(np.shape(child_connectivity_matrix)[0]):\n",
    "                    for col in range(np.shape(child_connectivity_matrix)[1]):\n",
    "                        child_connectivity_matrix[row][col] = father_gene.connectivity_matrix[row][col] \\\n",
    "                            if (random.uniform(0, 1) < 0.5) else mother_gene.connectivity_matrix[row][col]\n",
    "\n",
    "                layers.append(Layer(\n",
    "                    connectivity_matrix=child_connectivity_matrix,\n",
    "                    bias=child_bias,\n",
    "                    activation_function=child_activation_function,\n",
    "                ))\n",
    "\n",
    "            children.append(Network(layers))\n",
    "\n",
    "        return children\n",
    "\n",
    "    def mutate(self, organisms):\n",
    "        for organism in organisms:\n",
    "            organism.mutate()\n",
    "\n",
    "    def breed(self):\n",
    "        parents = self.selection()\n",
    "        children = self.crossover(parents)\n",
    "        self.mutate(children)\n",
    "        self.organisms = children + [self.elite]\n",
    "        self.generation += 1\n",
    "        self.history.append((self.max_fitness(), self.average_fitness()))\n",
    "\n",
    "    def plot(self):\n",
    "        plt.figure()\n",
    "        plt.plot(np.arange(self.generation + 1), [score[0] for score in self.history],\n",
    "                 label='max fitness')\n",
    "        plt.plot(np.arange(self.generation + 1), [score[1] for score in self.history],\n",
    "                 label='avg fitness', alpha=0.6)\n",
    "        plt.title('Population fitness' + ' (n=' + str(self.size) + ')')\n",
    "        plt.xlabel('Generations')\n",
    "        plt.ylabel('Fitness score (accuracy)')\n",
    "        plt.legend()\n",
    "        plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Training**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# initialization\n",
    "GENERATIONS = 50\n",
    "POPULATION_SIZE = 10\n",
    "SURVIVORS = 5\n",
    "population = Population(size=POPULATION_SIZE, n_survivors=SURVIVORS)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training\n",
      "Gen 0 : [0.1132, 0.1138, 0.0775, 0.0652, 0.1642, 0.123, 0.131, 0.1208, 0.066, 0.1157] - max: 0.1642 (25.35s)\n",
      "evaluation time: 21.121s\n",
      "Gen 1 : [0.1032, 0.0679, 0.0892, 0.0892, 0.0892, 0.0974, 0.101, 0.1028, 0.1028, 0.1642] - max: 0.1642 (54.85s)\n",
      "evaluation time: 20.286s\n",
      "Gen 2 : [0.0892, 0.0958, 0.1135, 0.0974, 0.1009, 0.101, 0.1135, 0.0974, 0.1028, 0.1642] - max: 0.1642 (52.0s)\n",
      "evaluation time: 20.273s\n",
      "Gen 3 : [0.0974, 0.0892, 0.0974, 0.098, 0.1135, 0.1009, 0.1028, 0.0958, 0.0892, 0.1642] - max: 0.1642 (51.23s)\n",
      "evaluation time: 20.693s\n",
      "Gen 4 : [0.0828, 0.1032, 0.1305, 0.098, 0.0892, 0.1135, 0.0716, 0.0958, 0.098, 0.1642] - max: 0.1642 (52.2s)\n",
      "evaluation time: 20.24s\n",
      "Gen 5 : [0.1028, 0.0982, 0.0892, 0.104, 0.0864, 0.098, 0.101, 0.1032, 0.0876, 0.1642] - max: 0.1642 (51.47s)\n",
      "evaluation time: 21.179s\n",
      "Gen 6 : [0.063, 0.0892, 0.1102, 0.101, 0.1304, 0.0892, 0.098, 0.0624, 0.1028, 0.1642] - max: 0.1642 (53.12s)\n",
      "evaluation time: 20.324s\n",
      "Gen 7 : [0.0892, 0.1025, 0.0974, 0.0958, 0.0892, 0.1032, 0.1003, 0.098, 0.0984, 0.1642] - max: 0.1642 (51.63s)\n",
      "evaluation time: 21.158s\n",
      "Gen 8 : [0.098, 0.1009, 0.098, 0.101, 0.0934, 0.1028, 0.1032, 0.0892, 0.124, 0.1642] - max: 0.1642 (53.37s)\n",
      "evaluation time: 21.743s\n",
      "Gen 9 : [0.1325, 0.1028, 0.098, 0.098, 0.0958, 0.1032, 0.0733, 0.1009, 0.134, 0.1642] - max: 0.1642 (54.88s)\n",
      "evaluation time: 21.24s\n",
      "Gen 10 : [0.098, 0.101, 0.0982, 0.1072, 0.101, 0.1028, 0.1009, 0.098, 0.0919, 0.1642] - max: 0.1642 (54.06s)\n",
      "evaluation time: 21.34s\n",
      "Gen 11 : [0.0982, 0.1028, 0.0982, 0.0933, 0.1032, 0.1009, 0.098, 0.1032, 0.0379, 0.1642] - max: 0.1642 (53.07s)\n",
      "evaluation time: 20.933s\n",
      "Gen 12 : [0.1032, 0.0958, 0.0974, 0.098, 0.098, 0.0958, 0.101, 0.098, 0.1135, 0.1642] - max: 0.1642 (52.54s)\n",
      "evaluation time: 20.447s\n",
      "Gen 13 : [0.1032, 0.0958, 0.0958, 0.1135, 0.1009, 0.1032, 0.1135, 0.1009, 0.0982, 0.1642] - max: 0.1642 (52.21s)\n",
      "evaluation time: 21.279s\n",
      "Gen 14 : [0.1028, 0.1135, 0.098, 0.0974, 0.1032, 0.1009, 0.1009, 0.098, 0.1135, 0.1642] - max: 0.1642 (52.43s)\n",
      "evaluation time: 20.648s\n",
      "Gen 15 : [0.1135, 0.0905, 0.098, 0.0982, 0.0892, 0.098, 0.1135, 0.0892, 0.1032, 0.1642] - max: 0.1642 (52.74s)\n",
      "evaluation time: 20.058s\n",
      "Gen 16 : [0.1135, 0.098, 0.1135, 0.0892, 0.098, 0.0892, 0.0958, 0.1135, 0.1009, 0.1642] - max: 0.1642 (50.81s)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[1;32mIn [15]\u001B[0m, in \u001B[0;36m<cell line: 13>\u001B[1;34m()\u001B[0m\n\u001B[0;32m     18\u001B[0m \u001B[38;5;66;03m# evaluate new population\u001B[39;00m\n\u001B[0;32m     19\u001B[0m ta\u001B[38;5;241m=\u001B[39mtime\u001B[38;5;241m.\u001B[39mtime()\n\u001B[1;32m---> 20\u001B[0m population_fitness \u001B[38;5;241m=\u001B[39m \u001B[43mpopulation\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43morganism_fitness\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     21\u001B[0m max_fitness \u001B[38;5;241m=\u001B[39m population\u001B[38;5;241m.\u001B[39mmax_fitness()\n\u001B[0;32m     22\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mevaluation time: \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124ms\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\u001B[38;5;28mround\u001B[39m(time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m-\u001B[39m ta, \u001B[38;5;241m3\u001B[39m)))\n",
      "Input \u001B[1;32mIn [13]\u001B[0m, in \u001B[0;36mPopulation.organism_fitness\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     29\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21morganism_fitness\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m---> 30\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m [organism\u001B[38;5;241m.\u001B[39mevaluate() \u001B[38;5;28;01mfor\u001B[39;00m organism \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39morganisms]\n",
      "Input \u001B[1;32mIn [13]\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m     29\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21morganism_fitness\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m---> 30\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m [\u001B[43morganism\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mevaluate\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m organism \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39morganisms]\n",
      "Input \u001B[1;32mIn [12]\u001B[0m, in \u001B[0;36mNetwork.evaluate\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     12\u001B[0m accuracy \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m     13\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m x, y \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(X_test, y_test):\n\u001B[1;32m---> 14\u001B[0m     y_pred \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39margmax(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreshape\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m)  \u001B[38;5;66;03m# class with highest value\u001B[39;00m\n\u001B[0;32m     15\u001B[0m     y_true \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39margmax(y)\n\u001B[0;32m     16\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m y_pred \u001B[38;5;241m==\u001B[39m y_true:\n",
      "Input \u001B[1;32mIn [12]\u001B[0m, in \u001B[0;36mNetwork.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m      6\u001B[0m temp \u001B[38;5;241m=\u001B[39m \u001B[38;5;28minput\u001B[39m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m layer \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlayers:\n\u001B[1;32m----> 8\u001B[0m     temp \u001B[38;5;241m=\u001B[39m \u001B[43mlayer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtemp\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m temp\n",
      "Input \u001B[1;32mIn [11]\u001B[0m, in \u001B[0;36mLayer.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m     16\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[1;32m---> 17\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m activation_functions[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mactivation_function](\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconnectivity_matrix\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m@\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbias)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# initial population\n",
    "print('Starting training')\n",
    "t_training = time.time()\n",
    "population_fitness = population.organism_fitness()\n",
    "max_fitness = population.max_fitness()\n",
    "t2 = time.time()\n",
    "print('Gen', 0, ':',\n",
    "      population_fitness, '- max:',\n",
    "      max_fitness,\n",
    "      '({}s)'.format(round(t2 - t_training, 2)))\n",
    "\n",
    "# future populations\n",
    "for generation in range(1, GENERATIONS):\n",
    "    # breed new population\n",
    "    t1 = time.time()\n",
    "    population.breed()\n",
    "\n",
    "    # evaluate new population\n",
    "    ta=time.time()\n",
    "    population_fitness = population.organism_fitness()\n",
    "    max_fitness = population.max_fitness()\n",
    "    print('evaluation time: {}s'.format(round(time.time() - ta, 3)))\n",
    "    t2 = time.time()\n",
    "\n",
    "    print('Gen', generation, ':',\n",
    "          population_fitness, '- max:',\n",
    "          max_fitness,\n",
    "          '({}s)'.format(round(t2 - t1, 2)))\n",
    "\n",
    "print('Finished training ({})'.format(round(time.time() - t_training, 2)))\n",
    "print('\\nTotal computation time: ({}s)'.format(round(time.time() - t0, 2)))\n",
    "\n",
    "# performance of population\n",
    "population.plot()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**DEBUGGING (multiprocessing)**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "from multiprocessing import Process\n",
    "\n",
    "def test(network):\n",
    "    network.evaluate()\n",
    "\n",
    "network1 = Network([\n",
    "    Layer(\n",
    "        connectivity_matrix=np.random.normal(loc=0.0, scale=1.0, size=(32, 784)),\n",
    "        bias=np.random.normal(loc=0.0, scale=1.0),\n",
    "        activation_function='sigmoid',\n",
    "        output_layer=False\n",
    "    ),\n",
    "    Layer(\n",
    "        connectivity_matrix=np.random.normal(loc=0.0, scale=1.0, size=(10, 32)),\n",
    "        bias=np.random.normal(loc=0.0, scale=1.0),\n",
    "        activation_function='softmax',\n",
    "        output_layer=True\n",
    "    )\n",
    "])\n",
    "network2 = Network([\n",
    "    Layer(\n",
    "        connectivity_matrix=np.random.normal(loc=0.0, scale=1.0, size=(32, 784)),\n",
    "        bias=np.random.normal(loc=0.0, scale=1.0),\n",
    "        activation_function='sigmoid',\n",
    "        output_layer=False\n",
    "    ),\n",
    "    Layer(\n",
    "        connectivity_matrix=np.random.normal(loc=0.0, scale=1.0, size=(10, 32)),\n",
    "        bias=np.random.normal(loc=0.0, scale=1.0),\n",
    "        activation_function='softmax',\n",
    "        output_layer=True\n",
    "    )\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Parallel"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "p1 = Process(target=test, args=(network1, ))\n",
    "p2 = Process(target=test, args=(network2, ))\n",
    "\n",
    "p1.start()\n",
    "p2.start()\n",
    "\n",
    "p1.join()\n",
    "p2.join()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Synchronous"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2.36 s\n",
      "Wall time: 2.53 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test(network1)\n",
    "test(network2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**DEBUGGING (GPU)**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cupy'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Input \u001B[1;32mIn [7]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mcupy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mcp\u001B[39;00m\n\u001B[0;32m      3\u001B[0m X \u001B[38;5;241m=\u001B[39m cp\u001B[38;5;241m.\u001B[39masarray(X_test)\n\u001B[0;32m      4\u001B[0m Y \u001B[38;5;241m=\u001B[39m cp\u001B[38;5;241m.\u001B[39masarray(y_test)\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'cupy'"
     ]
    }
   ],
   "source": [
    "import cupy as cp\n",
    "\n",
    "X = cp.asarray(X_test)\n",
    "Y = cp.asarray(y_test)\n",
    "\n",
    "def test_gpu(matrix1, bias1, activation1, matrix2, bias2, activation2):\n",
    "    accuracy = 0\n",
    "    for x, y in zip(X, Y):\n",
    "        out = activation_functions[activation2](\n",
    "                    bias2 + matrix2 @ activation_functions[activation1](\n",
    "                        bias1 + matrix1 @ x\n",
    "                    )\n",
    "                )\n",
    "\n",
    "        y_pred = cp.argmax(out)  # class with highest value\n",
    "        y_true = cp.argmax(y)\n",
    "        if y_pred == y_true:\n",
    "            accuracy += 1\n",
    "\n",
    "bias1 = cp.random.normal(loc=0.0, scale=1.0)\n",
    "matrix1 = cp.random.normal(loc=0.0, scale=1.0, size=(32, 784))\n",
    "activation1 = 'sigmoid'\n",
    "\n",
    "bias2 = cp.random.normal(loc=0.0, scale=1.0)\n",
    "matrix2 = cp.random.normal(loc=0.0, scale=1.0, size=(32, 784))\n",
    "activation2 = 'softmax'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X.device"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "test_gpu(matrix1, bias1, activation1, matrix2, bias2, activation2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}